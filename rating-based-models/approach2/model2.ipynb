{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QyKTgQAT6Sfw"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zVKV4EBw6TN7"
      },
      "outputs": [],
      "source": [
        "!pip install -r ../../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sbag5I1XKedJ"
      },
      "source": [
        "Read data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fw-l-krrLJ0b"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../../datasets/rating-based-dataset/data/ae_only_unambiguous_1000.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-d8b75f34b222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../datasets/rating-based-dataset/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mscores_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"data/ae_only_unambiguous_1000.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0m_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'website'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Abraham\\Proyectos\\website-aesthetics-research\\.venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Abraham\\Proyectos\\website-aesthetics-research\\.venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Abraham\\Proyectos\\website-aesthetics-research\\.venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Abraham\\Proyectos\\website-aesthetics-research\\.venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Abraham\\Proyectos\\website-aesthetics-research\\.venv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/rating-based-dataset/data/ae_only_unambiguous_1000.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_folder = '../../datasets/rating-based-dataset/'\n",
        "\n",
        "scores_data = pd.read_csv(data_folder + \"data/ae_only_unambiguous_1000.csv\", low_memory=False)\n",
        "\n",
        "_images = scores_data['website'].unique()\n",
        "_scores = scores_data.groupby('website')['mean_response'].apply(list)\n",
        "\n",
        "del scores_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gb_mWVp8LH0B"
      },
      "source": [
        "Get images path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u3XWHxswQA4-"
      },
      "outputs": [],
      "source": [
        "all_images = []\n",
        "scores = []\n",
        "images_path = data_folder + 'preprocess/resized'\n",
        "\n",
        "for image in _images:\n",
        "\n",
        "  # english websites\n",
        "  if 'english' in image:\n",
        "    all_images.append(images_path + '/english_resized/' + image[8:] + '.png')\n",
        "    scores.append(_scores[image])\n",
        "\n",
        "  # foreign websites\n",
        "  if 'foreign' in image:\n",
        "    all_images.append(images_path + '/foreign_resized/' + image[8:] + '.png')  \n",
        "    scores.append(_scores[image])\n",
        "\n",
        "print('Total number of images: %d' % len(all_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K_e6UsYcL8vC"
      },
      "source": [
        "Get the path of the images in test set and the ground truth user aesthetics ratings for each website. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OyuWYt-nIvAQ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "test_data_path = data_folder + 'preprocess/test_list.csv'\n",
        "\n",
        "def get_scores(scores_path):\n",
        "\n",
        "    images = []\n",
        "    scores = []\n",
        "\n",
        "    with open(scores_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        line_count = 0\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if line_count == 0:\n",
        "\n",
        "                line_count += 1\n",
        "            else:\n",
        "\n",
        "                scores.append(float(row[1]))\n",
        "                line_count += 1\n",
        "                image_name = row[0]\n",
        "\n",
        "                images.append(images_path + image_name)\n",
        "\n",
        "    return (images, scores)\n",
        "\n",
        "test_images_names, gt_scores = get_scores(test_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rJWRPcNfM3QQ"
      },
      "source": [
        "Form training and test data \n",
        "* {train, test}_images: contains the path of each image\n",
        "* {train, test}_scores: contains the user ratings of each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aNByZd3ySb2W"
      },
      "outputs": [],
      "source": [
        "train_images =[]\n",
        "train_scores =[]\n",
        "\n",
        "test_images = test_images_names\n",
        "test_scores = [[]] * len(test_images)\n",
        "\n",
        "for i in range(0, len(all_images)):\n",
        "  if all_images[i] in test_images_names:\n",
        "\n",
        "    pos = test_images_names.index(all_images[i])\n",
        "\n",
        "    test_scores[pos] = scores[i]\n",
        "  else:\n",
        "    train_images.append(all_images[i])\n",
        "    train_scores.append(scores[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cyw633FEN4tS"
      },
      "source": [
        "Shuffle the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PCe8KaAQTOvz"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# np.random.seed(2000)\n",
        "    \n",
        "temp = list(zip(train_images, train_scores))\n",
        "random.shuffle(temp)\n",
        "\n",
        "train_images, train_scores = zip(*temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_403SqrZODcP"
      },
      "source": [
        "Display the first 3 images to make sure everything is ok. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jpagl0HsTUEF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mping\n",
        "for ima in train_images[0:3]:\n",
        "  img = mping.imread(ima)\n",
        "  imgplot = plt.imshow(img)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e_7mRFO6OG7i"
      },
      "source": [
        "Read the images as numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dX0IUirtTaoL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "width = 256 \n",
        "height = 192 \n",
        "channels = 3\n",
        "\n",
        "def read_and_process_images(list_of_images):\n",
        "  X = []\n",
        "  \n",
        "  for image in list_of_images:\n",
        "\n",
        "    # images are already resized\n",
        "    # X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (width, height), \n",
        "    #                     interpolation=cv2.INTER_AREA))\n",
        "    X.append(cv2.imread(image, cv2.IMREAD_COLOR))\n",
        "\n",
        "  \n",
        "  return X\n",
        "\n",
        "\n",
        "X_train = np.array(read_and_process_images(train_images))\n",
        "X_val = np.array(read_and_process_images(test_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e6ZnqNCQOYyX"
      },
      "source": [
        "Display the first 3 images to make sure everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H4wDCyQ1Tk_B"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(25,15))\n",
        "columns = 3\n",
        "\n",
        "for i in range(columns):\n",
        "  plt.subplot(columns, 1, i+1)\n",
        "  plt.imshow(X_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hMPV71kvPv5V"
      },
      "source": [
        "The ground truth distribution of human ratings of a given website can be expressed as an empirical probability mass function **p** = [p<sub>s<sub>1</sub></sub>, p<sub>s<sub>2</sub></sub>, ..., p<sub>s<sub>N</sub></sub>] with s<sub>1</sub> &#8804; s<sub>i</sub> &#8804; s<sub>N</sub>, where s<sub>i</sub> denotes the i-th score bucket and N denotes the total number of buckets. In this case, s<sub>1</sub>=1 and s<sub>N</sub>=9.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iQcRQ0uGUdvp"
      },
      "outputs": [],
      "source": [
        "bins = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
        "score_values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0])\n",
        "\n",
        "y_train = []\n",
        "\n",
        "for i in range(0, len(train_scores)):\n",
        "  y_temp = np.histogram(train_scores[i], bins=bins)[0]\n",
        "  y_train.append(y_temp / len(train_scores[i]))\n",
        "  del y_temp\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "y_val = []\n",
        "\n",
        "for i in range(0, len(test_scores)):\n",
        "  y_temp = np.histogram(test_scores[i], bins=bins)[0]\n",
        "  y_val.append(y_temp / len(test_scores[i]))\n",
        "  del y_temp\n",
        "\n",
        "y_val = np.array(y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hI3pIgLcPR9V"
      },
      "source": [
        "Display shapes to check everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yzQsQb8jXR0O"
      },
      "outputs": [],
      "source": [
        "ntrain = len(X_train)\n",
        "nval = len(X_val)\n",
        "\n",
        "print('Shape of X_train is: ', X_train.shape)\n",
        "print('Shape of X_val is: ', X_val.shape)\n",
        "print('Shape of y_train is: ', y_train.shape)\n",
        "print('Shape of y_val is: ', y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uZOkPsEkUpEO"
      },
      "source": [
        "Construct the CNN. The task is to predict the user aesthetics score distribution for a website. We will use [NIMA-MobileNet](https://arxiv.org/pdf/1709.05424.pdf) as our base network. This network is pretrained on AVA dataset (containing 255k image with aesthetic quality ratings) for the neural image assessment task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "K6Q1cwyBXTf-"
      },
      "outputs": [],
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from keras.layers import GlobalMaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "input_shape = X_train[0].shape\n",
        "\n",
        "base_model = MobileNet(include_top=False, weights='imagenet', pooling='avg', input_shape=input_shape)\n",
        "\n",
        "x = base_model.output\n",
        "x = Dropout(0.6)(x) \n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "model.load_weights('../../pretrained-models/mobilenet_weights.h5')\n",
        "\n",
        "model.layers.pop()\n",
        "outputs = Dense(9, activation='softmax')(model.layers[-1].output)\n",
        "model = Model(inputs=model.input, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CEgCsP2BQQqC"
      },
      "source": [
        "Define the loss function (Earth Mover's Distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8dNk-tMUYqIO"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def earth_mover_loss(y_true, y_pred):\n",
        "    cdf_ytrue = K.cumsum(y_true, axis=-1)\n",
        "    cdf_ypred = K.cumsum(y_pred, axis=-1)\n",
        "    samplewise_emd = K.sqrt(K.mean(K.square(K.abs(cdf_ytrue - cdf_ypred)), axis=-1))\n",
        "    return K.mean(samplewise_emd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4CD7wYIIYo6N"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DKhZY81oRI0H"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MDQpMQmhYvvt"
      },
      "outputs": [],
      "source": [
        "epochs = 95\n",
        "decay = 1e-4 \n",
        "base_lr = 0.005\n",
        "\n",
        "sgd = optimizers.SGD(lr=base_lr, momentum=0.9, decay=decay, nesterov=True)\n",
        "model.compile(loss=earth_mover_loss, optimizer=sgd, metrics=[earth_mover_loss])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYlMYn33RjLb"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "j_YzT0JCY90w"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                             steps_per_epoch = ntrain // batch_size,\n",
        "                             epochs = epochs, \n",
        "                             validation_data=val_generator,\n",
        "                             validation_steps=nval // batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l1cjrIIFRgRu"
      },
      "source": [
        "Display the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WLPuiYC3ZIRo"
      },
      "outputs": [],
      "source": [
        "\n",
        "emd = history.history[\"earth_mover_loss\"]\n",
        "val_emd = history.history[\"val_earth_mover_loss\"]\n",
        "\n",
        "epochs_x = range(1, len(emd) + 1)\n",
        "\n",
        "plt.plot(epochs_x, emd, 'b', label='Training EMD')\n",
        "plt.plot(epochs_x, val_emd, 'r', label='Validation EMD')\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lViPMAw6RlWj"
      },
      "source": [
        "Define a function that calculates Pearson correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aGVyHN0WcWVG"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def pearsonr_ci(x,y,alpha=0.05):\n",
        "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy\n",
        "    Parameters\n",
        "    ----------\n",
        "    x, y : iterable object such as a list or np.array\n",
        "      Input for correlation calculation\n",
        "    alpha : float\n",
        "      Significance level. 0.05 by default\n",
        "    Returns\n",
        "    -------\n",
        "    r : float\n",
        "      Pearson's correlation coefficient\n",
        "    pval : float\n",
        "      The corresponding p value\n",
        "    lo, hi : float\n",
        "      The lower and upper bound of confidence intervals\n",
        "    '''\n",
        "    N = len(x)\n",
        "    r, p = stats.pearsonr(x,y)\n",
        "    r_z = np.arctanh(r)\n",
        "    se = 1/np.sqrt(N-3)\n",
        "    z = stats.norm.ppf(1-alpha/2)\n",
        "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
        "    lo, hi = np.tanh((lo_z, hi_z))\n",
        "    return r, p, lo, hi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fv4ksCj26_D0"
      },
      "source": [
        "Predict aesthetics score of the webpages in the test set. The mean value of the predicted distribution is used as the final aesthetics score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ANebT-tBcfOn"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "X_val = X_val / 255.0\n",
        "\n",
        "for img in X_val:\n",
        "  img = img.reshape(1, 192, 256, 3)\n",
        "  pred = model.predict(img)\n",
        "\n",
        "  predictions.append(float(np.sum(pred[0] * score_values)))\n",
        "\n",
        "gt_scores = np.array(gt_scores)\n",
        "predictions = np.array(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yeM28l7kZ4Ti"
      },
      "source": [
        "Display some websites of the test set and the predicted aesthetics score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NJJW6_BlGO5_"
      },
      "outputs": [],
      "source": [
        "image_ids = [87, 45, 49, 94, 14, 83] # test image IDs sorted in descending order according to the website's aesthetics level\n",
        "\n",
        "fig = plt.figure(figsize=(12, 16))\n",
        "i = 1\n",
        "for id in image_ids:\n",
        "  if 'english' in test_images[id]:\n",
        "    path = images_path + '/english_resized/' + test_images[id].rsplit('/', 1)[1]\n",
        "  else:\n",
        "    path = images_path + '/foreign_resized/' + test_images[id].rsplit('/', 1)[1]\n",
        " \n",
        "  plt.subplot(len(image_ids)/2, 2, i)\n",
        "  img = mping.imread(path)\n",
        "  plt.title('User average rating: ' + str(np.round(gt_scores[id],2)) + '\\nPredicted rating: ' + str(np.round(predictions[id],2)) + '\\n(' + chr(97+i-1) + ')', y=-0.25)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "    \n",
        "  i += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZLAvK-W6R_Ye"
      },
      "source": [
        "Create a scatterplot to check the relationship between ground truth and predicted scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MT2GU-J5c5a8"
      },
      "outputs": [],
      "source": [
        "from numpy.polynomial.polynomial import polyfit\n",
        "b, m = polyfit(gt_scores, predictions, 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.scatter(gt_scores, predictions, c='c')\n",
        "plt.plot(gt_scores, b + m * gt_scores, '-', c='b')\n",
        "plt.xlabel('User ratings')\n",
        "plt.ylabel('Predicted ratings')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b_copvG3R2oE"
      },
      "source": [
        "Calculate the Pearson correlation and the RMSE between ground truth and predicted scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nJJ2uK50c6No"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "corr, p, lo, hi = pearsonr_ci(gt_scores, predictions)\n",
        "print('Pearsons correlation: r=%.2f, p=%.2e, CI=[%.2f, %.2f]' % (corr, p, lo, hi))\n",
        "rmse_test = sqrt(mean_squared_error(gt_scores, predictions))\n",
        "print('RMSE: %.3f' % rmse_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iTcz-4TaSF7g"
      },
      "source": [
        "Plot the distribution of ground truth scores and the distribution of predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H2wRKCK7klRo"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure()\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "bins = np.linspace(1, 9, num=15)\n",
        "\n",
        "sns.distplot(gt_scores, bins=bins, label='User ratings')\n",
        "\n",
        "sns.distplot(predictions, bins=bins, label='Predicted ratings')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
